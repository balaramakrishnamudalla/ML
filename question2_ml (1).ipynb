{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc42081",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8976\\4129185522.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "from keras.layers import Dense, Flatten\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to your image folders\n",
    "train_path = \"C:/Users/hp/Documents/Mtech/GurNum/GurNum\"\n",
    "val_path = \"C:/Users/hp/Documents/Mtech/GurNum/GurNum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the folder containing the 'train' folder\n",
    "data_dir = train_path\n",
    "# Set the image size\n",
    "img_size = (32, 32)\n",
    "# Create empty lists for the images and labels\n",
    "images = []\n",
    "labels = []\n",
    "# Loop over each folder from '0' to '9'\n",
    "for label in range(10):\n",
    "    folder_path = os.path.join(data_dir, 'train', str(label))\n",
    "     # Loop over each image in the folder\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if file_path.endswith(('.tiff','.bmp')):\n",
    "             # Load the image and resize it to the desired size\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, img_size)\n",
    "            # Append the image and label to the lists\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "            \n",
    "# Convert the lists to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "# Save the arrays in NumPy format\n",
    "np.save('x_train.npy', images)\n",
    "np.save('y_train.npy', labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08922218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the folder containing the 'val' folder\n",
    "data_dir_val = val_path\n",
    "# Set the image size\n",
    "img_size_val = (32, 32)\n",
    "# Create empty lists for the images and labels\n",
    "images_val = []\n",
    "labels_val = []\n",
    "# Loop over each folder from '0' to '9'\n",
    "for label in range(10):\n",
    "    folder_path = os.path.join(data_dir_val, 'val\\\\', str(label))\n",
    "\n",
    "    # Loop over each image in the folder\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if file_path.endswith(('.tiff','.bmp')):\n",
    "            # Load the image and resize it to the desired size\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, img_size_val)\n",
    "            # Append the image and label to the lists\n",
    "            images_val.append(img)\n",
    "            labels_val.append(label)\n",
    "# Convert the lists to NumPy arrays\n",
    "images_val = np.array(images_val)\n",
    "labels_val = np.array(labels_val)\n",
    "# Save the arrays in NumPy format\n",
    "np.save('x_test.npy', images_val)\n",
    "np.save('y_test.npy', labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbfd007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "x1_train = np.load('x_train.npy')\n",
    "y1_train = np.load('y_train.npy')\n",
    "x1_test = np.load('x_test.npy')\n",
    "y1_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the images are loaded correctly\n",
    "print(len(x1_train))\n",
    "print(len(x1_test))\n",
    "x1_train[0].shape\n",
    "x1_train[0]\n",
    "plt.matshow(x1_train[0])\n",
    "plt.matshow(x1_train[999])\n",
    "print(x1_train.shape)\n",
    "print(x1_test.shape)\n",
    "y1_train\n",
    "y1_test\n",
    "plt.matshow(x1_test[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498cf2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, input_shape=(1024,),activation = 'sigmoid')\n",
    "])\n",
    "# compile the nn\n",
    "model.compile(optimizer='adam',\n",
    " loss='sparse_categorical_crossentropy',\n",
    " metrics=['accuracy']\n",
    " )\n",
    "# train the model\n",
    "# some 10 iterations done here\n",
    "model.fit(x1_train, y1_train,epochs= 10, validation_data=(x1_test, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train_scaled = x1_train/255\n",
    "x1_test_scaled = x1_test/255\n",
    "model.fit(x1_train_scaled, y1_train,epochs= 10, validation_data=(x1_test_scaled, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_scaled,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba7c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 1st image\n",
    "plt.matshow(x_test[0])\n",
    "y1_predicted = model.predict(x_test_scaled)\n",
    "y1_predicted[0]\n",
    "# this showing the 10 results for the input '0', we need to look for the value which is max\n",
    "print('Predicted Value is ',np.argmax(y1_predicted[0]))\n",
    "# test some more values\n",
    "plt.matshow(x1_test[88])\n",
    "print('Predicted Value is ',np.argmax(y1_predicted[88]))\n",
    "plt.matshow(x1_test[177])\n",
    "print('Predicted Value is ',np.argmax(y1_predicted[177]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2baa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to concrete values\n",
    "y1_predicted_labels=[np.argmax(i) for i in y_predicted]\n",
    "print(y1_predicted_labels, len(y1_predicted_labels))\n",
    "conf_mat = tf.math.confusion_matrix(labels=y1_test, predictions=y1_predicted_labels)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efaa988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,10))\n",
    "sn.heatmap(conf_mat,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    " keras.layers.Flatten(),\n",
    " keras.layers.Dense(1024,input_shape=(1024,), activation='relu'),\n",
    " keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "# compile the nn\n",
    "model2.compile(optimizer='adam',\n",
    " loss='sparse_categorical_crossentropy',\n",
    " metrics=['accuracy']\n",
    " )\n",
    "# train the model\n",
    "# some 10 iterations done here\n",
    "history = model2.fit(x1_train_scaled, y1_train,epochs= 10, validation_data=(x1_test_scaled, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate test dataset on modified model\n",
    "model2.evaluate(x1_test_scaled,y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf866b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build confusion matrix to see how our prediction looks like\n",
    "# convert to concrete values\n",
    "y1_predicted = model2.predict(x1_test_scaled)\n",
    "y1_predicted[0]\n",
    "y1_predicted_labels=[np.argmax(i) for i in y_predicted]\n",
    "print(y1_predicted_labels, len(y1_predicted_labels))\n",
    "conf_mat = tf.math.confusion_matrix(labels=y1_test, predictions=y1_predicted_labels)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sn.heatmap(conf_mat,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94524a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x1_test, y1_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ec040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01d3820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
